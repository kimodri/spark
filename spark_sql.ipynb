{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6978e758-9960-4d43-81b7-02ca8ae05bc2",
   "metadata": {},
   "source": [
    "# PySpark SQL\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d5fdc-f3dc-4cd2-833f-ad0bb27a963b",
   "metadata": {},
   "source": [
    "## Spark SQL\n",
    "- Module in Apache spark for structured data processing\n",
    "- Allows us to run SQL queries alongside data processing tasks\n",
    "- Seamless combination of python and SQL in one application\n",
    "- DataFrame interfacing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dc030c-f97f-46d0-8d08-18a8aad60d04",
   "metadata": {},
   "source": [
    "### Staring with Spark SQL\n",
    "- Initialize a session\n",
    "- create a dataframe\n",
    "\n",
    "```python\n",
    "spark = SparkSession.builder.appName(\"Spark SQL Example\").getOrCreate()\n",
    "\n",
    "# data\n",
    "# ... data about people (a dataframe)\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "```\n",
    "- Create a temp table\n",
    "    - Temporary views exists only for the current session, making them idea for quick, session-based exploration\n",
    "```python\n",
    "df.createOrReplaceTempView(\"people\")\n",
    "```\n",
    "- Query using SQL\n",
    "```python\n",
    "result.spark.sql(\"SELECT Name, Age FROM people WHERE Age > 30\")\n",
    "result.show()\n",
    "```\n",
    "See the \"people\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c20adb2-0955-4659-9b33-ceb2a90ffee1",
   "metadata": {},
   "source": [
    "### Temp Views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55601ca-8fc6-410a-89ca-41ceba01d75c",
   "metadata": {},
   "source": [
    "- Temp views protect the underlying data while doing analytics\n",
    "- Loading from a csv methods\n",
    "\n",
    "```python\n",
    "df = spark.read.csv(\"path\")\n",
    "df.createOrReplaceTempView(\"employees\")  # This allows sql based interaction\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5815b1-0571-450c-92d6-9f9dd9dd7e4f",
   "metadata": {},
   "source": [
    "## Casting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4069545e-dc17-4aa1-a059-95458df7ff50",
   "metadata": {},
   "source": [
    "Let's say you have string for integers, you can do this:\n",
    "```python\n",
    "data = [('HR', '3000'), ('IT', '40000'), ('Finance', '350000')]\n",
    "columns = [\"Department\", \"Salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "\n",
    "df = df.withColumn(\"Salary\", df['salary'].cast(\"int\"))\n",
    "\n",
    "df.groupBy(\"Department\").sum(\"Salary\").show()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
